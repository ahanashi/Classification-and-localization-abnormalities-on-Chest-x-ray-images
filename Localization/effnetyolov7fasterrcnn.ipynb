{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n<span style=\"color: #00857e; font-family: Segoe UI; font-size: 1.8em; font-weight: 300;\">Overview</span>\n\n&nbsp;&nbsp;‚úÖ&nbsp;&nbsp;EfficientNetV2 TF Model Study Level Inference on GPU with Keras<br>\n&nbsp;&nbsp;‚úÖ&nbsp;&nbsp;CascadeRCNN Image Level Inference on GPU with MMDetection<br>\n\n<br>\n<p style='text-align: left;'><span style=\"color: #000508; font-family: Segoe UI; font-size: 1.1em; font-weight: 600;\"> üè∑Ô∏è Dataset with EffNetV2 TfHub Weights used in this notebook:</span></p>\n\n\n>  [EfficientNetV2 TFHub Weight Files](https://www.kaggle.com/sreevishnudamodaran/efficientnetv2-tfhub-weight-files?select=tfhub_models)<br>\n  Official EfficientNetV2 Saved Model Files from tfhub.dev\n\n<br>\n<p style='text-align: left;'><span style=\"color: #000508; font-family: Segoe UI; font-size: 1.1em; font-weight: 600;\"> üè∑Ô∏è EffNetV2 Keras Study Level Train notebook:</span></p>\n\n\n>  [SIIM EffNetV2 Keras Study Train [TPU CV0.805+]üéè](https://www.kaggle.com/sreevishnudamodaran/siim-effnetv2-keras-study-train-tpu-cv0-805)<br>\n  Official EfficientNetV2 Saved Model Files from tfhub.dev\n\n<br>\n<p style='text-align: left;'><span style=\"color: #000508; font-family: Segoe UI; font-size: 1.1em; font-weight: 600;\"> üè∑Ô∏è MMDetection CascadeRCNN Image Level Train notebook:</span></p>\n\n\n>  [SIIM MMDetection+CascadeRCNN+Weight&Bias‚òÑÔ∏èüîÆ](https://www.kaggle.com/sreevishnudamodaran/siim-mmdetection-cascadercnn-weight-bias)<br>\n  Official EfficientNetV2 Saved Model Files from tfhub.dev\n\n<br>\n\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.8em;\">References:</span>\n\n- https://www.kaggle.com/h053473666/siim-cov19-efnb7-yolov5-infer\n- https://github.com/tensorflow/hub\n- https://github.com/open-mmlab/mmdetection\n","metadata":{"papermill":{"duration":0.026785,"end_time":"2021-07-17T18:53:20.688374","exception":false,"start_time":"2021-07-17T18:53:20.661589","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Others","metadata":{}},{"cell_type":"code","source":"\n%load_ext autoreload\n%autoreload 2\n\n!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -y --offline\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -y --offline\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -y --offline\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -y --offline\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -y --offline\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -y --offline\n\n!pip install '/kaggle/input/kerasapplications' --no-deps\n!pip install '/kaggle/input/efficientnet-keras-source-code' --no-deps\n!pip install '/kaggle/input/effdet-latestvinbigdata-wbf-fused/ensemble_boxes-1.0.4-py3-none-any.whl' --no-deps\n\n## MMDetection compatible torch installation\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchaudio-0.7.0-cp37-cp37m-linux_x86_64.whl' --no-deps\n\n## Compatible Cuda Toolkit installation\n!mkdir -p /kaggle/tmp && cp /kaggle/input/pytorch-170-cuda-toolkit-110221/cudatoolkit-11.0.221-h6bb024c_0 /kaggle/tmp/cudatoolkit-11.0.221-h6bb024c_0.tar.bz2 && conda install /kaggle/tmp/cudatoolkit-11.0.221-h6bb024c_0.tar.bz2 -y --offline\n\n## MMDetection Offline Installation\n!pip install '/kaggle/input/mmdetectionv2140/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmcv_full-1_3_8-cu110-torch1_7_0/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/pycocotools-2.0.2/pycocotools-2.0.2' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps\n\n!cp -r /kaggle/input/mmdetectionv2140/mmdetection-2.14.0 /kaggle/working/\n!mv /kaggle/working/mmdetection-2.14.0 /kaggle/working/mmdetection\n%cd /kaggle/working/mmdetection\n!pip install -e . --no-deps\n%cd /kaggle/working/\n","metadata":{"papermill":{"duration":589.21781,"end_time":"2021-07-17T19:03:09.933611","exception":false,"start_time":"2021-07-17T18:53:20.715801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:14:57.624108Z","iopub.execute_input":"2023-04-13T15:14:57.624414Z","iopub.status.idle":"2023-04-13T15:25:31.509168Z","shell.execute_reply.started":"2023-04-13T15:14:57.624338Z","shell.execute_reply":"2023-04-13T15:25:31.507831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working/mmdetection')\n\nimport os\nfrom PIL import Image\nimport pandas as pd\nimport gc\nfrom tqdm import tqdm\nimport glob","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.104274,"end_time":"2021-07-17T19:03:10.131834","exception":false,"start_time":"2021-07-17T19:03:10.02756","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:25:31.511036Z","iopub.execute_input":"2023-04-13T15:25:31.511384Z","iopub.status.idle":"2023-04-13T15:25:31.544300Z","shell.execute_reply.started":"2023-04-13T15:25:31.511342Z","shell.execute_reply":"2023-04-13T15:25:31.543435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #00857e; font-family: Segoe UI; font-size: 1.8em; font-weight: 300;\">Create Study and Image Level Dataframes</span>","metadata":{"papermill":{"duration":0.092535,"end_time":"2021-07-17T19:03:10.317337","exception":false,"start_time":"2021-07-17T19:03:10.224802","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\n\n# Form study and image dataframes\nsub_df['level'] = sub_df.id.map(lambda idx: idx[-5:])\nstudy_df = sub_df[sub_df.level=='study'].rename({'id':'study_id'}, axis=1)\nimage_df = sub_df[sub_df.level=='image'].rename({'id':'image_id'}, axis=1)\n\ndcm_path = glob.glob('/kaggle/input/siim-covid19-detection/test/**/*dcm', recursive=True)\ntest_meta = pd.DataFrame({'dcm_path':dcm_path})\ntest_meta['image_id'] = test_meta.dcm_path.map(lambda x: x.split('/')[-1].replace('.dcm', '')+'_image')\ntest_meta['study_id'] = test_meta.dcm_path.map(lambda x: x.split('/')[-3].replace('.dcm', '')+'_study')\n\nstudy_df = study_df.merge(test_meta, on='study_id', how='left')\nimage_df = image_df.merge(test_meta, on='image_id', how='left')\n\n# Remove duplicates study_ids from study_df\nstudy_df.drop_duplicates(subset=\"study_id\",keep='first', inplace=True)","metadata":{"papermill":{"duration":5.695531,"end_time":"2021-07-17T19:03:16.105354","exception":false,"start_time":"2021-07-17T19:03:10.409823","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:25:31.546127Z","iopub.execute_input":"2023-04-13T15:25:31.546518Z","iopub.status.idle":"2023-04-13T15:25:45.455008Z","shell.execute_reply.started":"2023-04-13T15:25:31.546460Z","shell.execute_reply":"2023-04-13T15:25:45.454165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #00857e; font-family: Segoe UI; font-size: 1.8em; font-weight: 300;\">Fast or Full Predictions</span>\n\nIn case of non-competetion submission commits, we run the notebook with just two images each for image level and study level inference from the public test data.","metadata":{"papermill":{"duration":0.154867,"end_time":"2021-07-17T19:03:16.415952","exception":false,"start_time":"2021-07-17T19:03:16.261085","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fast_sub = False\n\nif sub_df.shape[0] == 2477:\n    fast_sub = True\n    study_df = study_df.sample(2)\n    image_df = image_df.sample(2)\n    \n    print(\"\\nstudy_df\")\n    display(study_df.head(2))\n    print(\"\\nimage_df\")\n    display(image_df.head(2))\n    print(\"\\ntest_meta\")\n    display(test_meta.head(2))","metadata":{"papermill":{"duration":0.28084,"end_time":"2021-07-17T19:03:16.86864","exception":false,"start_time":"2021-07-17T19:03:16.5878","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:25:45.456557Z","iopub.execute_input":"2023-04-13T15:25:45.457072Z","iopub.status.idle":"2023-04-13T15:25:45.517599Z","shell.execute_reply.started":"2023-04-13T15:25:45.457036Z","shell.execute_reply":"2023-04-13T15:25:45.516644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:25:45.518879Z","iopub.execute_input":"2023-04-13T15:25:45.519217Z","iopub.status.idle":"2023-04-13T15:25:45.546950Z","shell.execute_reply.started":"2023-04-13T15:25:45.519180Z","shell.execute_reply":"2023-04-13T15:25:45.545981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nSTUDY_DIMS = (768, 768)\nIMAGE_DIMS = (512, 512)\n\nstudy_dir = f'/kaggle/tmp/test/study/'\nos.makedirs(study_dir, exist_ok=True)\n\nimage_dir = f'/kaggle/tmp/test/image/'\nos.makedirs(image_dir, exist_ok=True)\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\ndef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    return im\n\nfor index, row in tqdm(study_df[['study_id', 'dcm_path']].iterrows(), total=study_df.shape[0]):\n    # set keep_ratio=True to have original aspect ratio\n    xray = read_xray(row['dcm_path'])\n    im = resize(xray, size=STUDY_DIMS[0])\n    im.save(os.path.join(study_dir, row['study_id']+'.png'))\n\nimage_df['dim0'] = -1\nimage_df['dim1'] = -1\n\nfor index, row in tqdm(image_df[['image_id', 'dcm_path', 'dim0', 'dim1']].iterrows(), total=image_df.shape[0]):\n    # set keep_ratio=True to have original aspect ratio\n    xray = read_xray(row['dcm_path'])\n    im = resize(xray, size=IMAGE_DIMS[0])  \n    im.save(os.path.join(image_dir, row['image_id']+'.png'))\n    image_df.loc[image_df.image_id==row.image_id, 'dim0'] = xray.shape[0]\n    image_df.loc[image_df.image_id==row.image_id, 'dim1'] = xray.shape[1]","metadata":{"papermill":{"duration":4.178244,"end_time":"2021-07-17T19:03:21.225656","exception":false,"start_time":"2021-07-17T19:03:17.047412","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:25:45.548251Z","iopub.execute_input":"2023-04-13T15:25:45.548609Z","iopub.status.idle":"2023-04-13T15:25:47.597004Z","shell.execute_reply.started":"2023-04-13T15:25:45.548574Z","shell.execute_reply":"2023-04-13T15:25:47.596039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study_df['image_path'] = study_dir+study_df['study_id']+'.png'\nimage_df['image_path'] = image_dir+image_df['image_id']+'.png'","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:25:47.599776Z","iopub.execute_input":"2023-04-13T15:25:47.600023Z","iopub.status.idle":"2023-04-13T15:25:47.642747Z","shell.execute_reply.started":"2023-04-13T15:25:47.599997Z","shell.execute_reply":"2023-04-13T15:25:47.641976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #00857e; font-family: Segoe UI; font-size: 1.8em; font-weight: 300;\">Custom Wrapper for Loading TFHub Model trained in TPU</span>\n\nSince the EffNetV2 Classifier models were trained on a TPU with the `tfhub.KerasLayer` formed with the handle argument as a GCS path, while loading the saved model for inference, the method tries to download the pre-trained weights from the definition of the layer from training i.e a GCS path.\n\nSince, inference notebooks don't have GCS and internet access, it is not possible to load the model without the pretrained weights explicitly loaded from the local directory.\n\nIf the models were trained on a GPU, we can use the cache location method to load the pre-trained weights by storing them in a cache folder with the hashed key of the model location, as the folder name. I tried this method here but, it doesn't seem to work as the model was trained with a GCS path defined in the `tfhub.KerasLayer` and the method kept on hitting the GCS path rather than loading the weights from the cache location.\n\nThe only solution was to create a wrapper class to correct the handle argument to load the right pretrained weights explicitly from the local directory.","metadata":{"papermill":{"duration":0.096404,"end_time":"2021-07-17T19:03:21.416262","exception":false,"start_time":"2021-07-17T19:03:21.319858","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as tfhub\n\nMODEL_ARCH = 'efficientnetv2-l-21k-ft1k'\n# Get the TensorFlow Hub model URL\nhub_type = 'feature_vector' # ['classification', 'feature_vector']\nMODEL_ARCH_PATH = f'/kaggle/input/efficientnetv2-tfhub-weight-files/tfhub_models/{MODEL_ARCH}/{hub_type}'\n\n# Custom wrapper class to load the right pretrained weights explicitly from the local directory\nclass KerasLayerWrapper(tfhub.KerasLayer):\n    def __init__(self, handle, **kwargs):\n        handle = tfhub.KerasLayer(tfhub.load(MODEL_ARCH_PATH))\n        super().__init__(handle, **kwargs)","metadata":{"papermill":{"duration":4.259738,"end_time":"2021-07-17T19:03:25.768808","exception":false,"start_time":"2021-07-17T19:03:21.50907","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:25:47.645441Z","iopub.execute_input":"2023-04-13T15:25:47.645907Z","iopub.status.idle":"2023-04-13T15:25:51.780362Z","shell.execute_reply.started":"2023-04-13T15:25:47.645877Z","shell.execute_reply":"2023-04-13T15:25:51.779523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #00857e; font-family: Segoe UI; font-size: 1.8em; font-weight: 300;\">Predict Study Level</span>","metadata":{"papermill":{"duration":0.087465,"end_time":"2021-07-17T19:03:25.943841","exception":false,"start_time":"2021-07-17T19:03:25.856376","status":"completed"},"tags":[]}},{"cell_type":"code","source":"MODEL_PATH = '/kaggle/input/siim-effnetv2-keras-study-train-tpu-cv0-805'\ntest_paths = study_df.image_path.tolist()\nBATCH_SIZE = 16\n\ndef build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.image.resize(img, target_size)\n\n        return img\n\n    def decode_with_labels(path, label):\n        return decode(path), label\n\n    return decode_with_labels if with_labels else decode\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        return img\n\n    def augment_with_labels(img, label):\n        return augment(img), label\n\n    return augment_with_labels if with_labels else augment\n\ndef build_dataset(paths, labels=None, bsize=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\"):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n\n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n\n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n\n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n\n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize).prefetch(AUTO)\n\n    return dset\n\n# strategy = auto_select_accelerator()\n# BATCH_SIZE = strategy.num_replicas_in_sync * 16\n\nlabel_cols = ['negative', 'typical', 'indeterminate', 'atypical']\nstudy_df[label_cols] = 0\n\ntest_decoder = build_decoder(with_labels=False,\n                             target_size=(STUDY_DIMS[0],\n                                          STUDY_DIMS[0]), ext='png')\ntest_dataset = build_dataset(\n    test_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder\n)\n\nwith tf.device('/device:GPU:0'):\n    models = []\n    models0 = tf.keras.models.load_model(f'{MODEL_PATH}/model0.h5',\n                                         custom_objects={'KerasLayer': KerasLayerWrapper})\n    models1 = tf.keras.models.load_model(f'{MODEL_PATH}/model1.h5',\n                                         custom_objects={'KerasLayer': KerasLayerWrapper})\n    models2 = tf.keras.models.load_model(f'{MODEL_PATH}/model2.h5',\n                                         custom_objects={'KerasLayer': KerasLayerWrapper})\n    models3 = tf.keras.models.load_model(f'{MODEL_PATH}/model3.h5',\n                                         custom_objects={'KerasLayer': KerasLayerWrapper})\n    models4 = tf.keras.models.load_model(f'{MODEL_PATH}/model4.h5',\n                                         custom_objects={'KerasLayer': KerasLayerWrapper})\n    models.append(models0)\n    models.append(models1)\n    models.append(models2)\n    models.append(models3)\n    models.append(models4)\n\nstudy_df[label_cols] = sum([model.predict(test_dataset, verbose=1) for model in models]) / len(models)\nstudy_df['PredictionString'] = study_df[label_cols].apply(lambda row: f'negative {row.negative} 0 0 1 1 typical {row.typical} 0 0 1 1 indeterminate {row.indeterminate} 0 0 1 1 atypical {row.atypical} 0 0 1 1', axis=1)\n\ndel models\ndel models0, models1, models2, models3, models4\ndel test_dataset, test_decoder\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:25:51.782257Z","iopub.execute_input":"2023-04-13T15:25:51.782566Z","iopub.status.idle":"2023-04-13T15:29:08.869435Z","shell.execute_reply.started":"2023-04-13T15:25:51.782538Z","shell.execute_reply":"2023-04-13T15:29:08.868579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #00857e; font-family: Segoe UI; font-size: 1.8em; font-weight: 300;\">Predict 2Class Image Level</span>\n\nUsing [@Alien](https://www.kaggle.com/h053473666) 2class model.","metadata":{"papermill":{"duration":0.096091,"end_time":"2021-07-17T19:04:41.039546","exception":false,"start_time":"2021-07-17T19:04:40.943455","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import efficientnet.tfkeras as efn\n\nMODEL_PATH = '/kaggle/input/siim-covid19-efnb7-train-fold0-5-2class'\n\ntest_paths = image_df.image_path.tolist()\nimage_df['none'] = 0\nlabel_cols = ['none']\n\ntest_decoder = build_decoder(with_labels=False,\n                             target_size=(IMAGE_DIMS[0],\n                                          IMAGE_DIMS[0]), ext='png')\ntest_dataset = build_dataset(\n    test_paths, bsize=BATCH_SIZE, repeat=False, \n    shuffle=False, augment=False, cache=False,\n    decode_fn=test_decoder\n)\n\nwith tf.device('/device:GPU:0'):\n    models = []\n    models0 = tf.keras.models.load_model(f'{MODEL_PATH}/model0.h5')\n    models1 = tf.keras.models.load_model(f'{MODEL_PATH}/model1.h5')\n    models2 = tf.keras.models.load_model(f'{MODEL_PATH}/model2.h5')\n    models3 = tf.keras.models.load_model(f'{MODEL_PATH}/model3.h5')\n    models4 = tf.keras.models.load_model(f'{MODEL_PATH}/model4.h5')\n    models.append(models0)\n    models.append(models1)\n    models.append(models2)\n    models.append(models3)\n    models.append(models4)\n\nimage_df[label_cols] = sum([model.predict(test_dataset, verbose=1) for model in models]) / len(models)\n\ndel models\ndel models0, models1, models2, models3, models4\ndel test_dataset, test_decoder\ngc.collect()","metadata":{"papermill":{"duration":123.226242,"end_time":"2021-07-17T19:06:44.363338","exception":false,"start_time":"2021-07-17T19:04:41.137096","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:29:08.870979Z","iopub.execute_input":"2023-04-13T15:29:08.871329Z","iopub.status.idle":"2023-04-13T15:31:28.560140Z","shell.execute_reply.started":"2023-04-13T15:29:08.871290Z","shell.execute_reply":"2023-04-13T15:31:28.559298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #00857e; font-family: Segoe UI; font-size: 1.8em; font-weight: 300;\">Predict Image Level</span>","metadata":{"papermill":{"duration":0.094734,"end_time":"2021-07-17T19:06:44.55103","exception":false,"start_time":"2021-07-17T19:06:44.456296","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from numba import cuda\nimport torch\ncuda.select_device(0)\ncuda.close()\ncuda.select_device(0)","metadata":{"papermill":{"duration":2.426508,"end_time":"2021-07-17T19:06:47.070269","exception":false,"start_time":"2021-07-17T19:06:44.643761","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:31:28.561666Z","iopub.execute_input":"2023-04-13T15:31:28.562015Z","iopub.status.idle":"2023-04-13T15:31:31.109365Z","shell.execute_reply.started":"2023-04-13T15:31:28.561977Z","shell.execute_reply":"2023-04-13T15:31:31.108550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\nimport torch\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(device.type)\n\nimport torchvision\nprint(torch.__version__, torch.cuda.is_available())\n\n# Check mmcv installation\nfrom mmcv.ops import get_compiling_cuda_version, get_compiler_version\nprint(get_compiling_cuda_version())\nprint(get_compiler_version())\n\n# Check MMDetection installation\nfrom mmdet.apis import set_random_seed\n\n# Imports\nimport mmdet\nfrom mmdet.apis import set_random_seed\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\n\nimport mmcv\nfrom mmcv import Config\nfrom mmcv.runner import load_checkpoint\nfrom mmcv.parallel import MMDataParallel\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot\nfrom mmdet.apis import single_gpu_test\nfrom mmdet.datasets import build_dataloader, build_dataset","metadata":{"papermill":{"duration":24.187988,"end_time":"2021-07-17T19:07:11.351071","exception":false,"start_time":"2021-07-17T19:06:47.163083","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:31:31.110670Z","iopub.execute_input":"2023-04-13T15:31:31.111024Z","iopub.status.idle":"2023-04-13T15:31:52.593621Z","shell.execute_reply.started":"2023-04-13T15:31:31.110982Z","shell.execute_reply":"2023-04-13T15:31:52.592706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\nlabel2color = [[59, 238, 119]]\n\nviz_labels =  [\"Covid_Abnormality\"]\n\ndef plot_img(img, size=(18, 18), is_rgb=True, title=\"\", cmap=None):\n    plt.figure(figsize=size)\n    plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()\n    \ndef plot_imgs(imgs, cols=2, size=10, is_rgb=True, title=\"\", cmap=None, img_size=None):\n    rows = len(imgs)//cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    return fig\n    \ndef draw_bbox(image, box, label, color):   \n    alpha = 0.1\n    alpha_font = 0.6\n    thickness = 8\n    font_size = 2.0\n    font_weight = 1\n    overlay_bbox = image.copy()\n    overlay_text = image.copy()\n    output = image.copy()\n\n    text_width, text_height = cv2.getTextSize(label.upper(), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_weight)[0]\n    cv2.rectangle(overlay_bbox, (box[0], box[1]), (box[2], box[3]),\n                color, -1)\n    cv2.addWeighted(overlay_bbox, alpha, output, 1 - alpha, 0, output)\n    cv2.rectangle(overlay_text, (box[0], box[1]-18-text_height), (box[0]+text_width+8, box[1]),\n                (0, 0, 0), -1)\n    cv2.addWeighted(overlay_text, alpha_font, output, 1 - alpha_font, 0, output)\n    cv2.rectangle(output, (box[0], box[1]), (box[2], box[3]),\n                    color, thickness)\n    cv2.putText(output, label.upper(), (box[0], box[1]-12),\n            cv2.FONT_HERSHEY_SIMPLEX, font_size, (255, 255, 255), font_weight, cv2.LINE_AA)\n    return output\n\ndef draw_bbox_small(image, box, label, color):   \n    alpha = 0.1\n    alpha_text = 0.3\n    thickness = 1\n    font_size = 0.4\n    overlay_bbox = image.copy()\n    overlay_text = image.copy()\n    output = image.copy()\n\n    text_width, text_height = cv2.getTextSize(label.upper(), cv2.FONT_HERSHEY_SIMPLEX, font_size, thickness)[0]\n    cv2.rectangle(overlay_bbox, (box[0], box[1]), (box[2], box[3]),\n                color, -1)\n    cv2.addWeighted(overlay_bbox, alpha, output, 1 - alpha, 0, output)\n    cv2.rectangle(overlay_text, (box[0], box[1]-7-text_height), (box[0]+text_width+2, box[1]),\n                (0, 0, 0), -1)\n    cv2.addWeighted(overlay_text, alpha_text, output, 1 - alpha_text, 0, output)\n    cv2.rectangle(output, (box[0], box[1]), (box[2], box[3]),\n                    color, thickness)\n    cv2.putText(output, label.upper(), (box[0], box[1]-5),\n            cv2.FONT_HERSHEY_SIMPLEX, font_size, (255, 255, 255), thickness, cv2.LINE_AA)\n    return output","metadata":{"papermill":{"duration":0.117768,"end_time":"2021-07-17T19:07:28.313348","exception":false,"start_time":"2021-07-17T19:07:28.19558","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:31:52.595182Z","iopub.execute_input":"2023-04-13T15:31:52.595566Z","iopub.status.idle":"2023-04-13T15:31:52.685357Z","shell.execute_reply.started":"2023-04-13T15:31:52.595525Z","shell.execute_reply":"2023-04-13T15:31:52.684577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_cfg_path = \"/kaggle/input/siim-mmdetection-cascadercnn-weight-bias/job4_cascade_rcnn_x101_32x4d_fpn_1x_fold0/job4_cascade_rcnn_x101_32x4d_fpn_1x_coco.py\"\ncfg = Config.fromfile(baseline_cfg_path)\n\ncfg.classes = (\"Covid_Abnormality\")\ncfg.data.test.img_prefix = ''\ncfg.data.test.classes = cfg.classes\n\n# cfg.model.roi_head.bbox_head.num_classes = 1\n# cfg.model.bbox_head.num_classes = 1\nfor head in cfg.model.roi_head.bbox_head:\n    head.num_classes = 1\n\n# Set seed thus the results are more reproducible\ncfg.seed = 211\nset_random_seed(211, deterministic=False)\ncfg.gpu_ids = [0]\n\ncfg.data.test.pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip', direction='horizontal'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='DefaultFormatBundle'),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]\n\ncfg.test_pipeline = [\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip', direction='horizontal'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='DefaultFormatBundle'),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]\n\n# cfg.data.samples_per_gpu = 4\n# cfg.data.workers_per_gpu = 4\n# cfg.model.test_cfg.nms.iou_threshold = 0.3\ncfg.model.test_cfg.rcnn.score_thr = 0.001\n\nWEIGHTS_FILE = '/kaggle/input/siim-mmdetection-cascadercnn-weight-bias/job4_cascade_rcnn_x101_32x4d_fpn_1x_fold0/epoch_10.pth'\noptions = dict(classes = (\"Covid_Abnormality\"))\nmodel = init_detector(cfg, WEIGHTS_FILE, device='cuda:0')","metadata":{"papermill":{"duration":16.649888,"end_time":"2021-07-17T19:07:28.101611","exception":false,"start_time":"2021-07-17T19:07:11.451723","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:31:52.686818Z","iopub.execute_input":"2023-04-13T15:31:52.687223Z","iopub.status.idle":"2023-04-13T15:32:10.144137Z","shell.execute_reply.started":"2023-04-13T15:31:52.687153Z","shell.execute_reply":"2023-04-13T15:32:10.143229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ensemble_boxes import weighted_boxes_fusion, nms\n\nviz_images = []\nresults = []\nscore_threshold = cfg.model.test_cfg.rcnn.score_thr\n\ndef format_pred(boxes: np.ndarray, scores: np.ndarray, labels: np.ndarray) -> str:\n    pred_strings = []\n    label_str = ['opacity']\n    for label, score, bbox in zip(labels, scores, boxes):\n        xmin, ymin, xmax, ymax = bbox.astype(np.int64)\n        pred_strings.append(f\"{label_str[int(label)]} {score:.16f} {xmin} {ymin} {xmax} {ymax}\")\n    return \" \".join(pred_strings)\n\nmodel.to(device)\nmodel.eval()\n\nviz_images = []\n\nwith torch.no_grad():\n    for index, row in tqdm(image_df.iterrows(), total=image_df.shape[0]):\n        original_H, original_W = (int(row.dim0), int(row.dim1))\n        predictions = inference_detector(model, row.image_path)\n        boxes, scores, labels = (list(), list(), list())\n\n        for k, cls_result in enumerate(predictions):\n#             print(\"cls_result\", cls_result)\n            if cls_result.size != 0:\n                if len(labels)==0:\n                    boxes = np.array(cls_result[:, :4])\n                    scores = np.array(cls_result[:, 4])\n                    labels = np.array([k]*len(cls_result[:, 4]))\n                else:    \n                    boxes = np.concatenate((boxes, np.array(cls_result[:, :4])))\n                    scores = np.concatenate((scores, np.array(cls_result[:, 4])))\n                    labels = np.concatenate((labels, [k]*len(cls_result[:, 4])))\n                    \n            if fast_sub:\n                img_viz = cv2.imread(row.image_path)\n                for box, label, score in zip(boxes, labels, scores):\n                    color = label2color[int(label)]\n                    img_viz = draw_bbox_small(img_viz, box.astype(np.int32), f'opacity_{score:.4f}', color)\n                viz_images.append(img_viz)\n\n        indexes = np.where(scores > score_threshold)\n#         print(indexes)\n        boxes = boxes[indexes]\n        scores = scores[indexes]\n        labels = labels[indexes]\n\n        if len(labels) != 0:\n            h_ratio = original_H/IMAGE_DIMS[0]\n            w_ratio = original_W/IMAGE_DIMS[1]\n            boxes[:, [0, 2]] *= w_ratio\n            boxes[:, [1, 3]] *= h_ratio\n\n            result = {\n                \"id\": row.image_id,\n                \"PredictionString\": format_pred(\n                    boxes, scores, labels\n                ),\n            }\n\n            results.append(result)\ndel model\ngc.collect()\n\ndetection_df = pd.DataFrame(results, columns=['id', 'PredictionString'])\n\nif fast_sub:\n    display(detection_df.sample(2))\n    # Plot sample images\n    plot_imgs(viz_images, cmap=None)\n    plt.savefig('viz_fig_siim.png', bbox_inches='tight')\n    plt.show()","metadata":{"papermill":{"duration":2.481425,"end_time":"2021-07-17T19:07:30.8895","exception":false,"start_time":"2021-07-17T19:07:28.408075","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:32:10.145592Z","iopub.execute_input":"2023-04-13T15:32:10.146181Z","iopub.status.idle":"2023-04-13T15:32:12.636956Z","shell.execute_reply.started":"2023-04-13T15:32:10.146096Z","shell.execute_reply":"2023-04-13T15:32:12.635455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detection_df = pd.DataFrame(results, columns=['id', 'PredictionString'])","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:48:12.135355Z","iopub.execute_input":"2023-04-13T15:48:12.135742Z","iopub.status.idle":"2023-04-13T15:48:12.215256Z","shell.execute_reply.started":"2023-04-13T15:48:12.135701Z","shell.execute_reply":"2023-04-13T15:48:12.214212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detection_df = detection_df.merge(image_df[['image_id', 'none']].rename({'image_id':'id'}, axis=1),\n                                  on='id', how='left')","metadata":{"papermill":{"duration":0.130739,"end_time":"2021-07-17T19:07:31.131057","exception":false,"start_time":"2021-07-17T19:07:31.000318","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:12.436177Z","iopub.execute_input":"2023-04-13T15:48:12.436436Z","iopub.status.idle":"2023-04-13T15:48:12.515992Z","shell.execute_reply.started":"2023-04-13T15:48:12.436409Z","shell.execute_reply":"2023-04-13T15:48:12.515222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detection_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:48:13.081994Z","iopub.execute_input":"2023-04-13T15:48:13.082300Z","iopub.status.idle":"2023-04-13T15:48:13.167255Z","shell.execute_reply.started":"2023-04-13T15:48:13.082270Z","shell.execute_reply":"2023-04-13T15:48:13.166387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Yolo7","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:12.822270Z","iopub.execute_input":"2023-04-13T15:32:12.822680Z","iopub.status.idle":"2023-04-13T15:32:12.945825Z","shell.execute_reply.started":"2023-04-13T15:32:12.822642Z","shell.execute_reply":"2023-04-13T15:32:12.945009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:12.947053Z","iopub.execute_input":"2023-04-13T15:32:12.947379Z","iopub.status.idle":"2023-04-13T15:32:13.026548Z","shell.execute_reply.started":"2023-04-13T15:32:12.947345Z","shell.execute_reply":"2023-04-13T15:32:13.025317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:13.028071Z","iopub.execute_input":"2023-04-13T15:32:13.028623Z","iopub.status.idle":"2023-04-13T15:32:13.105682Z","shell.execute_reply.started":"2023-04-13T15:32:13.028585Z","shell.execute_reply":"2023-04-13T15:32:13.104856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split = 'test'\nsave_dir = f'/kaggle/tmp/{split}/'\n\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'/kaggle/tmp/{split}/study/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray('/kaggle/input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')\n    im = resize(xray, size=600)  \n    study = '00086460a852' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    xray = read_xray('/kaggle/input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')\n    im = resize(xray, size=600)  \n    study = '000c9c05fd14' + '_study.png'\n    im.save(os.path.join(save_dir, study))\nelse:   \n    for dirname, _, filenames in tqdm(os.walk(f'/kaggle/input/siim-covid19-detection/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=600)  \n            study = dirname.split('/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:13.107053Z","iopub.execute_input":"2023-04-13T15:32:13.107522Z","iopub.status.idle":"2023-04-13T15:32:13.894873Z","shell.execute_reply.started":"2023-04-13T15:32:13.107468Z","shell.execute_reply":"2023-04-13T15:32:13.893986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id = []\ndim0 = []\ndim1 = []\nsplits = []\nsave_dir = f'/kaggle/tmp/{split}/image/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray('/kaggle/input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')\n    im = resize(xray, size=512)  \n    im.save(os.path.join(save_dir,'65761e66de9f_image.png'))\n    image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\n    xray = read_xray('/kaggle/input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')\n    im = resize(xray, size=512)  \n    im.save(os.path.join(save_dir, '51759b5579bc_image.png'))\n    image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\nelse:\n    for dirname, _, filenames in tqdm(os.walk(f'/kaggle/input/siim-covid19-detection/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=512)  \n            im.save(os.path.join(save_dir, file.replace('.dcm', '_image.png')))\n            image_id.append(file.replace('.dcm', ''))\n            dim0.append(xray.shape[0])\n            dim1.append(xray.shape[1])\n            splits.append(split)\n\nmeta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:13.896371Z","iopub.execute_input":"2023-04-13T15:32:13.896735Z","iopub.status.idle":"2023-04-13T15:32:14.261589Z","shell.execute_reply.started":"2023-04-13T15:32:13.896698Z","shell.execute_reply":"2023-04-13T15:32:14.260673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\nif df.shape[0] == 2477:\n    fast_sub = True\n    fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n                         ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n                         ['65761e66de9f_image', 'none 1 0 0 1 1'], \n                         ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n                       columns=['id', 'PredictionString'])\nelse:\n    fast_sub = False","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:14.265182Z","iopub.execute_input":"2023-04-13T15:32:14.265451Z","iopub.status.idle":"2023-04-13T15:32:14.358166Z","shell.execute_reply.started":"2023-04-13T15:32:14.265424Z","shell.execute_reply":"2023-04-13T15:32:14.357386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta = meta[meta['split'] == 'test']\nif fast_sub:\n    test_df = fast_df.copy()\nelse:\n    test_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\n\n\nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\n\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]\ntest_df = df[study_len:].reset_index(drop=True) \n\nmeta['image_id'] = meta['image_id'] + '_image'\nmeta.columns = ['id', 'dim0', 'dim1', 'split']\ntest_df = pd.merge(test_df, meta, on = 'id', how = 'left')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:14.359805Z","iopub.execute_input":"2023-04-13T15:32:14.360150Z","iopub.status.idle":"2023-04-13T15:32:14.471636Z","shell.execute_reply.started":"2023-04-13T15:32:14.360114Z","shell.execute_reply":"2023-04-13T15:32:14.470840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!rm -r /kaggle/working/yolov7","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:14.472800Z","iopub.execute_input":"2023-04-13T15:32:14.473121Z","iopub.status.idle":"2023-04-13T15:32:14.549465Z","shell.execute_reply.started":"2023-04-13T15:32:14.473086Z","shell.execute_reply":"2023-04-13T15:32:14.548531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dim = 512 #1024, 256, 'original'\ntest_dir = f'/kaggle/tmp/{split}/image'\nweights_dir = '/kaggle/input/yolov7-trained/best.pt'\n\nshutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov7')\nos.chdir('/kaggle/working/yolov7') # install dependencies\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:14.550896Z","iopub.execute_input":"2023-04-13T15:32:14.551306Z","iopub.status.idle":"2023-04-13T15:32:14.960149Z","shell.execute_reply.started":"2023-04-13T15:32:14.551270Z","shell.execute_reply":"2023-04-13T15:32:14.959257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport torch\n#from IPython.display import Image, clear_output  # to display images\n\n#clear_output()\n#print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n\n\n!python /kaggle/input/yolov7-lib/yolov7-main/detect.py --weights $weights_dir\\\n--img 512\\\n--conf 0.001\\\n--iou 0.5\\\n--source $test_dir\\\n--save-txt --save-conf --exist-ok\ndef yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n\n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n\n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n\n    return bboxes\n","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:14.961396Z","iopub.execute_input":"2023-04-13T15:32:14.961753Z","iopub.status.idle":"2023-04-13T15:32:37.287767Z","shell.execute_reply.started":"2023-04-13T15:32:14.961714Z","shell.execute_reply":"2023-04-13T15:32:37.286232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ids = []\nPredictionStrings = []\n\nfor file_path in tqdm(glob('runs/detect/exp/labels/*.txt')):\n    image_id = file_path.split('/')[-1].split('.')[0]\n    if (test_df.id==image_id).sum() > 0:\n        w, h = test_df.loc[test_df.id==image_id,['dim1', 'dim0']].values[0]\n        f = open(file_path, 'r')\n        data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n        data = data[:, [0, 5, 1, 2, 3, 4]]\n\n        bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n\n        bboxes = [bbox if bbox!='nan' else '0' for bbox in bboxes]\n        for idx in range(len(bboxes)):\n            bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n        image_ids.append(image_id)\n        PredictionStrings.append(' '.join(bboxes))\n\n\npred_df = pd.DataFrame({'id':image_ids,\n                        'PredictionString':PredictionStrings})","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:37.289568Z","iopub.execute_input":"2023-04-13T15:32:37.290197Z","iopub.status.idle":"2023-04-13T15:32:37.438135Z","shell.execute_reply.started":"2023-04-13T15:32:37.290152Z","shell.execute_reply":"2023-04-13T15:32:37.437565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble","metadata":{}},{"cell_type":"code","source":"'''\ntest_df = detection_df.copy()\ntest_df = test_df.drop(['PredictionString'], axis=1)\nsub_df = pd.merge(test_df, pred_df, on = 'id', how = 'left').fillna(\"none 1 0 0 1 1\")\nsub_df = sub_df[['id', 'PredictionString']]\nfor i in range(sub_df.shape[0]):\n    if sub_df.loc[i,'PredictionString'] == \"none 1 0 0 1 1\":\n        continue\n    sub_df_split = sub_df.loc[i,'PredictionString'].split()\n    sub_df_list = []\n    for j in range(int(len(sub_df_split) / 6)):\n        sub_df_list.append('opacity')\n        sub_df_list.append(sub_df_split[6 * j + 1])\n        sub_df_list.append(sub_df_split[6 * j + 2])\n        sub_df_list.append(sub_df_split[6 * j + 3])\n        sub_df_list.append(sub_df_split[6 * j + 4])\n        sub_df_list.append(sub_df_split[6 * j + 5])\n    sub_df.loc[i,'PredictionString'] = ' '.join(sub_df_list)\nsub_df['none'] = test_df['none'] \nfor i in range(sub_df.shape[0]):\n    if sub_df.loc[i,'PredictionString'] != 'none 1 0 0 1 1':\n        sub_df.loc[i,'PredictionString'] = sub_df.loc[i,'PredictionString'] + ' none ' + str(sub_df.loc[i,'none']) + ' 0 0 1 1'\nsub_df = sub_df[['id', 'PredictionString']]   \ndetection_df = detection_df[:study_len]\ndetection_df = detection_df.append(sub_df).reset_index(drop=True)\ndetection_df.to_csv('/kaggle/working/submission.csv',index = False)  \nshutil.rmtree('/kaggle/working/yolov7')\n'''","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:32:37.439270Z","iopub.execute_input":"2023-04-13T15:32:37.439790Z","iopub.status.idle":"2023-04-13T15:32:37.520550Z","shell.execute_reply.started":"2023-04-13T15:32:37.439751Z","shell.execute_reply":"2023-04-13T15:32:37.519557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#detection_df_['PredictionString'] = detection_df_['PredictionString_y'].fillna(detection_df_['PredictionString_x'])\n#detection_df_.drop(['PredictionString_x', 'PredictionString_y'], axis=1, inplace=True)\n#detection_df_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#detection_df = pd.merge(detection_df, pred_df, on=['id', 'PredictionString'], how='outer')\n#detection_df","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:44:57.060407Z","iopub.execute_input":"2023-04-13T15:44:57.060778Z","iopub.status.idle":"2023-04-13T15:44:57.149812Z","shell.execute_reply.started":"2023-04-13T15:44:57.060740Z","shell.execute_reply":"2023-04-13T15:44:57.148937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i in range(detection_df.shape[0]):\n    if detection_df.loc[i,'PredictionString'] != 'none 1 0 0 1 1':\n        detection_df.loc[i,'PredictionString'] = detection_df.loc[i,'PredictionString'] + ' none ' + str(detection_df.loc[i,'none']) + ' 0 0 1 1'\ndetection_df = detection_df[['id', 'PredictionString']]\n\nresults_df = study_df[['study_id', 'PredictionString']].rename({'study_id':'id'}, axis=1)\nresults_df = results_df.append(detection_df[['id', 'PredictionString']])\nresults_df.append(pred_df[['id', 'PredictionString']])","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:48:20.863923Z","iopub.execute_input":"2023-04-13T15:48:20.864342Z","iopub.status.idle":"2023-04-13T15:48:20.960486Z","shell.execute_reply.started":"2023-04-13T15:48:20.864292Z","shell.execute_reply":"2023-04-13T15:48:20.959510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\nsub_df['PredictionString'] = np.nan\nsub_df = sub_df.set_index('id')\nresults_df = results_df.set_index('id')\nsub_df.update(results_df)\nsub_df = sub_df.reset_index()\nsub_df = sub_df.fillna(\"none 1 0 0 1 1\")\nsub_df.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"papermill":{"duration":0.305787,"end_time":"2021-07-17T19:07:31.547349","exception":false,"start_time":"2021-07-17T19:07:31.241562","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:48:35.848786Z","iopub.execute_input":"2023-04-13T15:48:35.849120Z","iopub.status.idle":"2023-04-13T15:48:35.943950Z","shell.execute_reply.started":"2023-04-13T15:48:35.849087Z","shell.execute_reply":"2023-04-13T15:48:35.943060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if fast_sub:\n    display(sub_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:48:40.063148Z","iopub.execute_input":"2023-04-13T15:48:40.063492Z","iopub.status.idle":"2023-04-13T15:48:40.147461Z","shell.execute_reply.started":"2023-04-13T15:48:40.063442Z","shell.execute_reply":"2023-04-13T15:48:40.146596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')\nsub_df['PredictionString'] = np.nan\n# sub_df = sub_df.set_index('id')\nsub_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T15:49:34.489715Z","iopub.execute_input":"2023-04-13T15:49:34.490040Z","iopub.status.idle":"2023-04-13T15:49:34.581375Z","shell.execute_reply.started":"2023-04-13T15:49:34.490010Z","shell.execute_reply":"2023-04-13T15:49:34.580356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r /kaggle/working/mmdetection","metadata":{"papermill":{"duration":0.363451,"end_time":"2021-07-17T19:07:32.023003","exception":false,"start_time":"2021-07-17T19:07:31.659552","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T15:49:40.590150Z","iopub.execute_input":"2023-04-13T15:49:40.590509Z","iopub.status.idle":"2023-04-13T15:49:40.999149Z","shell.execute_reply.started":"2023-04-13T15:49:40.590454Z","shell.execute_reply":"2023-04-13T15:49:40.998060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style='text-align: center;'><span style=\"color: #000508; font-family: Segoe UI; font-size: 2.4em; font-weight: 300;\">HAVE A GREAT DAY!</span></p>\n\n<p style='text-align: center;'><span style=\"color: #000508; font-family: Segoe UI; font-size: 1.4em; font-weight: 300;\">Let me know if you have any suggestions!</span></p>","metadata":{}}]}